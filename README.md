# LIME-SHAP  - ML and AI Model Explainability and Interpretability
 Developing Inuition of Explainability and Interpretability using LIME and SHAP Libraries

 #Explainability is a process of answering the why's in the models decision making. For example a model providing an explanation into the reason a particular node in the tree was split and how it was split.

On the other hand, Interpretability is a process that is involved with answering what's involved in the decision making. It helps Data Scientists understand things such as weights and coefficients contributing towards model predictions. 

As the AI and ML models are becoming more and more complex with hundreds of model layers and thousands to billions of parameters for example in LLM and deep learning models, it becomes extremely difficult for us to understand the model's overall decision making. Thus, it becomes imperative for Data Scientists and AI Experts to leverage explainability techniques into their model building process and this would also improve the model's interpretability.


## Tools to Improve ML and AI Model Explainability and Interpretability:

Any tool that provides information into the models decision making process and the features contributions in model predictions is very helpful. Explanations can be made more intuitive through visualizations.

Through this code, we will explore two of the popularly used external tools to add ML and AI model explainability and interpretability
LIME (Local Interpretable Model-Agnostic Explanations)
SHAP (SHapely Additive exPlanations)

Please feel free to visit my blog where I have discussed the ML and AI Explainability and Interpretability.

https://medium.com/@diwale.varsha/ml-and-ai-model-explainability-and-interpretability-5b04935aac19

Thank you!

